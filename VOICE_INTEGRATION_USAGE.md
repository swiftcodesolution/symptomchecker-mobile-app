# Enhanced Voice Integration Usage Guide

## ðŸŽ¯ Features Implemented

### âœ… Voice Input with Audio Feedback
- **Click voice button** â†’ Voice recognition starts
- **Real-time transcript** â†’ Shows what you're saying
- **Audio response** â†’ AI speaks back with ChatGPT-5 voice
- **Smooth flow** â†’ One voice completes before next starts

### âœ… ChatGPT-5 Voice Integration
- **High-quality voice** â†’ Uses OpenAI's latest voice model
- **Natural speech** â†’ Sounds like ChatGPT-5
- **Audio queue** â†’ Smooth playback without interruptions

## ðŸš€ How to Use

### 1. Basic Integration in Your Component

```javascript
import { AIService } from '../utils/aiService'

// In your component
useEffect(() => {
  // Setup event handlers
  AIService.setEventHandlers({
    onTranscript: (transcript) => {
      console.log('User said:', transcript)
      // Update UI with transcript
    },
    onResponse: (responseData, type) => {
      if (type === 'text') {
        console.log('AI text response:', responseData)
        // Update UI with text response
      }
    },
    onAudioStart: () => {
      console.log('AI started speaking')
      // Show speaking indicator
    },
    onAudioComplete: () => {
      console.log('AI finished speaking')
      // Hide speaking indicator
    },
    onError: (error) => {
      console.error('Voice error:', error)
      // Handle errors
    }
  })

  // Initialize connection
  AIService.initializeRealtimeConnection(
    conversationHistory,
    medicationContext,
    patientProfile
  )
}, [])
```

### 2. Voice Button Handler

```javascript
const handleVoiceButtonPress = async () => {
  if (isSpeaking) {
    Alert.alert("Please wait", "AI is currently speaking")
    return
  }

  if (isListening) {
    // Stop listening and send message
    await ExpoSpeechRecognitionModule.stop()
    if (voiceInputText.trim()) {
      AIService.sendTextMessage(voiceInputText.trim())
    }
  } else {
    // Start listening
    await startListening()
  }
}
```

### 3. Using EnhancedVoiceChat Component

```javascript
import EnhancedVoiceChat from '../components/EnhancedVoiceChat'

const MyComponent = () => {
  const [conversationHistory, setConversationHistory] = useState([])
  const [medicationContext, setMedicationContext] = useState('')
  const [patientProfile, setPatientProfile] = useState('')

  return (
    <EnhancedVoiceChat
      conversationHistory={conversationHistory}
      medicationContext={medicationContext}
      patientProfile={patientProfile}
      onTranscript={(transcript) => {
        console.log('Transcript:', transcript)
      }}
      onResponse={(response, type) => {
        console.log('Response:', response, type)
      }}
      onError={(error) => {
        console.error('Error:', error)
      }}
    />
  )
}
```

## ðŸ”§ Configuration Options

### Voice Settings
```javascript
// In AIService.sendSessionConfig()
{
  voice: "alloy", // ChatGPT-5 voice
  voice_settings: {
    stability: 0.5,
    similarity_boost: 0.8
  }
}
```

### Audio Processing
```javascript
// Process audio for realtime API
const processedAudio = await AIService.processAudioForRealtime(audioBuffer)
AIService.sendAudioData(processedAudio)
AIService.commitAudioBuffer()
```

## ðŸ“± UI States

### Connection Status
- **Disconnected** â†’ Red dot, "Disconnected"
- **Connecting** â†’ Orange dot, "Connecting..."
- **Connected** â†’ Green dot, "Connected"
- **Listening** â†’ Green dot, "Listening..."
- **Processing** â†’ Orange dot, "Processing..."
- **AI Speaking** â†’ Red dot, "AI Speaking..."

### Button States
- **Ready** â†’ Gray button, "Tap to Speak"
- **Listening** â†’ Green button, "Tap to Send"
- **Speaking** â†’ Red button, "AI Speaking..."
- **Processing** â†’ Orange button, "Processing..."

## ðŸŽµ Audio Features

### Smooth Playback
- **Audio Queue** â†’ Multiple audio chunks play smoothly
- **No Interruptions** â†’ One audio completes before next starts
- **Visual Feedback** â†’ Wave animations during speaking

### Voice Quality
- **PCM16 Format** â†’ High-quality audio
- **16kHz Sample Rate** â†’ Optimal for voice
- **Real-time Processing** â†’ Low latency

## ðŸ› Troubleshooting

### Common Issues

1. **Voice not working**
   ```javascript
   // Check connection status
   const status = AIService.getConnectionStatus()
   console.log('Connected:', status.isConnected)
   ```

2. **Audio not playing**
   ```javascript
   // Check audio status
   const audioStatus = AIService.getAudioStatus()
   console.log('Playing:', audioStatus.isPlaying)
   console.log('Queue:', audioStatus.queueLength)
   ```

3. **Connection errors**
   ```javascript
   // Reinitialize connection
   AIService.closeConnection()
   await AIService.initializeRealtimeConnection(...)
   ```

### Debug Mode
```javascript
// Enable detailed logging
AIService.setEventHandlers({
  onTranscript: (transcript) => console.log('ðŸŽ¤ Transcript:', transcript),
  onResponse: (response, type) => console.log('ðŸ¤– Response:', response, type),
  onAudioStart: () => console.log('ðŸ”Š Audio started'),
  onAudioComplete: () => console.log('âœ… Audio completed'),
  onError: (error) => console.error('âŒ Error:', error)
})
```

## ðŸ“Š Performance Tips

### 1. Connection Management
```javascript
// Initialize once, reuse connection
useEffect(() => {
  const initConnection = async () => {
    await AIService.initializeRealtimeConnection(...)
  }
  initConnection()
  
  return () => {
    // Only close on component unmount
    AIService.closeConnection()
  }
}, [])
```

### 2. Audio Processing
```javascript
// Process audio in chunks for better performance
const processAudioChunk = async (audioBuffer) => {
  const processedAudio = await AIService.processAudioForRealtime(audioBuffer)
  if (processedAudio) {
    AIService.sendAudioData(processedAudio)
  }
}
```

### 3. Memory Management
```javascript
// Clear audio queue when needed
AIService.audioQueue = []
AIService.stopAudioPlayback()
```

## ðŸŽ¯ Best Practices

### 1. User Experience
- **Visual Feedback** â†’ Show connection status
- **Audio Indicators** â†’ Wave animations during speaking
- **Error Handling** â†’ Graceful error messages
- **Loading States** â†’ Show processing indicators

### 2. Performance
- **Connection Reuse** â†’ Don't reconnect unnecessarily
- **Audio Queue** â†’ Smooth playback
- **Memory Cleanup** â†’ Clear resources when done

### 3. Error Handling
- **Network Issues** â†’ Retry connection
- **Audio Errors** â†’ Fallback to text
- **Permission Issues** â†’ Request microphone access

## ðŸ”„ Integration with Existing Code

### Replace Current Voice Implementation
```javascript
// Old way
const handleSendMessage = async (text, isFromVoice) => {
  // ... existing code
  Speech.speak(aiResponseText, { ... })
}

// New way
const handleSendMessage = async (text, isFromVoice) => {
  // ... existing code
  if (isFromVoice && AIService.getConnectionStatus().isConnected) {
    AIService.sendTextMessage(text)
    // Audio will play automatically via Realtime API
  } else {
    Speech.speak(aiResponseText, { ... })
  }
}
```

### Update Voice Button
```javascript
const isVoiceButtonDisabled = isSpeaking || isLoading || AIService.getAudioStatus().isPlaying
```

## ðŸŽ‰ Result

Now you have:
- âœ… **Voice input** with real-time feedback
- âœ… **ChatGPT-5 voice** responses
- âœ… **Smooth audio flow** - one completes before next starts
- âœ… **Visual indicators** for all states
- âœ… **Error handling** and recovery
- âœ… **High-quality audio** with proper processing

The voice experience is now smooth, natural, and provides excellent user feedback! ðŸš€

